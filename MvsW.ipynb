{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wJYdVsfYO4G",
        "outputId": "16f61681-0901-454a-a24b-bbfc8866b6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/\"\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtxCm5DvkYkB",
        "outputId": "56bb4efd-2f9d-447e-f5ee-790a82fac775"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "'12 arquetipos.gdoc'\n",
            "'1 Actividad Introducción Sostenibilidad_TAS_MPG.docx'\n",
            "'1.- THE_FUTURE_OF_MOOCS.gsheet'\n",
            " 4-3.PNG\n",
            "'A01703259_Evidencia 1.gdoc'\n",
            " A01703259_Evidencia1.gdoc\n",
            " A01703259_Evidencia2_Proyecto.gdoc\n",
            " A01703259ITITC.gsheet\n",
            " A01703259_Ricardo_Nuñez\n",
            " AAAAAAAAAAAA.gdoc\n",
            " ACR_11y12_Mate_Int.gdoc\n",
            " ACT_1_Mate_Int.gdoc\n",
            " ACT_3_Mate_Int.gdoc\n",
            " Act3ST.gdoc\n",
            "'Act 5.2.gdoc'\n",
            "'Actividad 2_Equipo B.gdoc'\n",
            "'Actividad 2 Reto.gdoc'\n",
            "'Actividad del módulo 1: Fundamentos de la Administración de Proyectos.gdoc'\n",
            "'Actividad Glucógeno(1).docx'\n",
            " Actualización-del-PVE-AD17.docx\n",
            "'Administración profesional y ágil de proyectos.gdoc'\n",
            " ADRHA.gslides\n",
            "'Advanced English 4'\n",
            "'Advanced English I'\n",
            "'Advanced English V'\n",
            "'Advanced English VI'\n",
            " Analisis_A01703259.docx\n",
            "'Análisis de la materia implementación de métodos computacionales.pptx'\n",
            "'Anemia falciforme.docx'\n",
            " Animación\n",
            "'Apac Queretaro.gdoc'\n",
            "'April 22.gdoc'\n",
            "'Arte, Camara y Combat Mechanics.gdoc'\n",
            " Arturo\n",
            " asd.zip\n",
            "'Autoevaluacion EGEL Plus ISOFT 2 A01703259.gsheet'\n",
            "'Autoevaluacion EGEL Plus ISOFT A01703259.gsheet'\n",
            "'Avance1 Zebrands.gslides'\n",
            " Baja.drawio\n",
            " Banci\n",
            " BenjiAsesoria\n",
            " Bienestar\n",
            " bien.gslides\n",
            " Bor.gdoc\n",
            " Calculoiluminacion.xlsx\n",
            " CasosDeUso.drawio\n",
            "'CCM VIDEOJUEGOS'\n",
            " Chatbot.gdoc\n",
            " Ciud.gdoc\n",
            " Clepsidra.gdoc\n",
            "'Colab Notebooks'\n",
            " Comp_A01703259_Final.gdoc\n",
            " Comp_A01703259.gdoc\n",
            "'Copia de 1st Oral Assignment DRAFT.pptx.gslides'\n",
            "'Copia de 3. THIRD_partial_writting_assignment_ADV VI.gdoc'\n",
            "'Copia de Actividad01.gdoc'\n",
            "'Copia de Avance2 Zebrands.gslides'\n",
            "'Copia de Copia de Mission for Book Clubs Pt 1 (Book Experts) (1).gdoc'\n",
            "'Copia de Copia de Mission for Book Clubs Pt 1 (Book Experts).gdoc'\n",
            "'Copia de Dog Pattern by Slidesgo'$'\\n''.gslides'\n",
            "'Copia de Experimento 2.gsheet'\n",
            "'Copia de FUNNY_PICS_ABOUT_GENDER_ISSUES_AND_TECHNOLOGY.gslides'\n",
            "'Copia de GENDER ISSUES REFLECTION.gsheet'\n",
            "'Copia de LngP01.docx'\n",
            "'Copia de LngP01.gdoc'\n",
            "'Copia de LngP02.gdoc'\n",
            "'Copia de Mission for Book Clubs Pt 0 (Cover Page).gdoc'\n",
            "'Copia de Pretty Aesthetic Notes for School | by Slidesgo'$'\\n''.gslides'\n",
            "'Copia de Qué leo, qué veo, qué escucho..gslides'\n",
            "'Copia de Sex_Roles_ACTIVITY.gsheet'\n",
            "'Copia de TUTO FINAL POR FIN.gdoc'\n",
            "'Copia de YA LO ÚLTIMO .gslides'\n",
            " coulomb.m\n",
            " CoworQDosISP.txt\n",
            " CoworQDosISPv2.txt\n",
            " CoworQDosISPv3.txt\n",
            " Creatividad\n",
            " cr.gdoc\n",
            "'Curso Pasado.gdoc'\n",
            "'D3_Esquema discurso persuasivo.docx'\n",
            " dhcplearn.txt\n",
            "'Diapositiva 4 Consolidación.gdoc'\n",
            " Diseñadores.gdoc\n",
            "'Documento sin título (1).gdoc'\n",
            "'Documento sin título (2).gdoc'\n",
            "'Documento sin título (3).gdoc'\n",
            "'Documento sin título (4).gdoc'\n",
            "'Documento sin título (5).gdoc'\n",
            "'Documento sin título.gdoc'\n",
            "'EGEL-ISOFT Descriptores.gsheet'\n",
            " Ej10.txt\n",
            " ej14vlan_A01703259.txt\n",
            " Ejer13.txt\n",
            "'El mito de la revolución.gdoc'\n",
            " English.gdoc\n",
            "'English VI'\n",
            "'entre 1 fismic.docx'\n",
            "'entre 1 fismic.docx - Gráfico de líneas 1.gsheet'\n",
            " Essay.docx.gdoc\n",
            " Estadistica.gdoc\n",
            "'Estándares Internacionales.gdoc'\n",
            "'Evidencia 1: Colaboración.gdoc'\n",
            "'Evidencia 3.gslides'\n",
            "'Evidencias Primer Periodo.gdoc'\n",
            "'Evolución de las computadoras.pptx'\n",
            "'Ex - Mate.gdoc'\n",
            " F127D305-F39E-4424-B0A9-84C6C47270A5.jpeg\n",
            " firstconfigpkt.txt\n",
            "'Física 2 pro.gdoc'\n",
            " FISMIC.gdoc\n",
            " Formateo\n",
            "'Formato para Guión Técnico.docx'\n",
            "'Formula minima y molecular (Act.2) (1).docx.gdoc'\n",
            "'Formula minima y molecular (Act.2).docx'\n",
            "'Formula minima y molecular (Act.2).docx.gdoc'\n",
            " Foro_Python.gdoc\n",
            " Fotos\n",
            "'Graffiti(3).docx'\n",
            "'Graffiti(3).gdoc'\n",
            " Guion.gdoc\n",
            "'Guion Literario.gdoc'\n",
            " HistoriaDeLasSexualidades_A01703259.gdoc\n",
            "'Hoja de cálculo sin título.gsheet'\n",
            " Horizontec.gdoc\n",
            " HumanoBlender\n",
            "'Ideas de propuesta.gdoc'\n",
            "'Ideas Propuestas.gslides'\n",
            " Ima\n",
            " IMG_5725.MOV\n",
            "'Ingles Wtring.gdoc'\n",
            "'Integración Delta.gform'\n",
            "'Integración Delta (respuestas).gsheet'\n",
            " Integradora5.3.gdoc\n",
            "'INVESTIGACIÓN SM64.gdoc'\n",
            "'Involucramiento Primer Periodo.gdoc'\n",
            " joc.gslides\n",
            " konce.txt\n",
            " LabUno.zip\n",
            "'LAS MUERTAS DE CIUDAD JUAREZ (Rubén Amador)                                                                '$'\\t''martes, 6 de julio de 2010.gdoc'\n",
            "'LAST PITCH.gslides'\n",
            "'Link a OneDrive 3 Mundos.gdoc'\n",
            " LngM02.gdoc\n",
            "'Lo lamento....gslides'\n",
            " M3_A01703259.gdoc\n",
            "'Mapa sin nombre (1).gmap'\n",
            "'Mapa sin nombre (2).gmap'\n",
            "'Mapa sin nombre.gmap'\n",
            "'Maquina de estados.gdoc'\n",
            " MarioMovie.gdoc\n",
            " Mariotte.gdoc\n",
            "'Medios_de _comunicación_A01703259.gdoc'\n",
            " Meiosis.pdf\n",
            "'Metricas sin Nombre One on One.gsheet'\n",
            " METRO_MDE.gdoc\n",
            "'Mi Botella de Mariotte.gdoc'\n",
            " Michexterior_ver2.jpg\n",
            " Michinterior_ver2.jpg\n",
            "'Mi experiencia en Delta.gform'\n",
            "'Mi propuesta de valor en el mundo laboral.gdoc'\n",
            "'Momox elipses.pdf'\n",
            " Museo.docx\n",
            " Museo.docx.gdoc\n",
            "'New Note (1).pdf'\n",
            "'New Note.pdf'\n",
            "'No entrar :c.gdoc'\n",
            " PCHORIZONTEC.gdoc\n",
            " PdT_IM.gsheet\n",
            " Pitch.gdoc\n",
            "'Plan de compes.gsheet'\n",
            "'Plan de Transformación.pptm'\n",
            "'Plan Lenguaje Oral.gsheet'\n",
            " PokeROMS.zip\n",
            "'Portafolio  de Evidencias PBB'\n",
            "'Preguntas Kahoot.gdoc'\n",
            "'Presentación sin título (1).gslides'\n",
            "'Presentación sin título (2).gslides'\n",
            "'Presentación sin título (3).gslides'\n",
            "'Presentación sin título.gslides'\n",
            " Presentation.pptx\n",
            " ProBuilder\n",
            "'Proyecto Diseño.gsheet'\n",
            "'proyecto quimica.gdoc'\n",
            "'proyecto quimica.pdf'\n",
            " pruebas.gdoc\n",
            " Puntualidad.gdoc\n",
            " QariñosEq3.gslides\n",
            " REFLEXIÓN_DÍA_1_A01703259.gdoc\n",
            " REFLEXIÓN_DÍA_2_A01703259.gdoc\n",
            " REFLEXIÓN_FINAL_A01703259.gdoc\n",
            " Reflexion.gdoc\n",
            " ReflexionUnityAgent.gdoc\n",
            "'Ref SH.gdoc'\n",
            "'Reto Bio.gdoc'\n",
            "'Reto Mate Computacional.gslides'\n",
            "'Ricardo Nunez y Fermín Mendez'\n",
            " Ricardo_Plan_de_Vida_Universitario.gsheet\n",
            " RioPass\n",
            " Robot\n",
            " Rpearson.gsheet\n",
            " Rpearson.xlsx\n",
            "'Rúbrica para la Evaluación de la Primera Entrega de Proyecto Teórico.docx'\n",
            " Salvador\n",
            " SculptGL\n",
            "'Segunda Parte.gdoc'\n",
            "'Self Activity (respuestas).gsheet'\n",
            " Sensores.gslides\n",
            " Shopping.doc\n",
            " Shopping.gdoc\n",
            " SP_MA1033.gdoc\n",
            " Storytelling.gdoc\n",
            "'tabal 3.xlsx'\n",
            " TablaDeFrecuencia.gdoc\n",
            " Tarea_2_Mate_Int.gdoc\n",
            " TC2008B_INTEGRATIVE.zip\n",
            " TC2008-Traffic-main.zip\n",
            " Tessellate\n",
            "'TÉTRADA DE SCHELL - SUPER MARIO Bros.gdoc'\n",
            " The-Language-of-the-Future.docx\n",
            " TicToc.mp4\n",
            " Timeline03.gdoc\n",
            "'Uber Activity.gdoc'\n",
            " Unity\n",
            " Unity3Lab.gdoc\n",
            " UnityLab1.gdoc\n",
            " Untitled0.ipynb\n",
            "'Untitled Diagram (1).drawio'\n",
            "'Untitled Diagram.drawio'\n",
            "'Untitled presentation.gslides'\n",
            " video\n",
            " Video_bienestar\n",
            " VideoFinal\n",
            " WATCHMEN.gsheet\n",
            "'WhatsApp Video 2021-11-30 at 5.58.32 PM.mp4'\n",
            " YO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "\n",
        "usamos ImageDataGenerator para generar imagenes nuevas en el ram mientras entrenamos para no desperdiciar espacio."
      ],
      "metadata": {
        "id": "RyRpvQCAj7aI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5bsMefaTK9A",
        "outputId": "68c01da0-e612-4988-d37f-81104575a3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4474 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "base_dir = 'Fotos'\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "\t\t\t\t\t\t\trescale = 1./255, #obligatorio\n",
        "\t\t\t\t\t\t\trotation_range = 40,\n",
        "\t\t\t\t\t\t\t#width_shift_range = 0.2,\n",
        "\t\t\t\t\t\t\t#height_shift_range = 0.2,\n",
        "\t\t\t\t\t\t\t#shear_range = 0.3,\n",
        "\t\t\t\t\t\t\tzoom_range = 0.3,\n",
        "\t\t\t\t\t\t\thorizontal_flip = True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\t\t\t\t\t\t\ttrain_dir,\n",
        "\t\t\t\t\t\t\ttarget_size = (150, 150),\n",
        "\t\t\t\t\t\t\tbatch_size = 128,\n",
        "\t\t\t\t\t\t\tclass_mode ='binary'\n",
        "\t\t\t\t\t\t\t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape = (150,150,3)))\n",
        "model.add(layers.MaxPooling2D())\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape = (150,150,3)))\n",
        "model.add(layers.MaxPooling2D())\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape = (150,150,3)))\n",
        "model.add(layers.MaxPooling2D())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "\t\t\t\t\t\toptimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "\t\t\t\t\t\tmetrics=['acc'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y2957UWm1Ka",
        "outputId": "7330e287-eafd-49ae-aa66-e52386bd7ba1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 18496)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               2367616   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2391329 (9.12 MB)\n",
            "Trainable params: 2391329 (9.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saHPzD9MXeF6",
        "outputId": "cd3dfb20-2608-4ad8-9ed9-61819d35c026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/35 [=======>......................] - ETA: 2:08 - loss: 0.7006 - acc: 0.4929"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "\t\t\t\t\t\ttrain_generator,\n",
        "\t\t\t\t\t\tepochs = 10)\n",
        "\n",
        "\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.plot(epochs,acc,'bo',label='train accuracy')\n",
        "plt.title('train acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs,loss, 'bo', label ='training loss')\n",
        "plt.title('train loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSHeXVn246UW",
        "outputId": "d9b568d8-ec62-4227-bd57-166f6945c9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 34 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py:1663: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2/25 [=>............................] - ETA: 1s - loss: 159.6962 - acc: 0.5588"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 25 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 0s 4ms/step - loss: 159.6962 - acc: 0.5588\n",
            "\n",
            "test acc :\n",
            " 0.5588235259056091\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "\t\t\t\t\ttest_dir,\n",
        "\t\t\t\t\ttarget_size = (150, 150),\n",
        "\t\t\t\t\tbatch_size = 64,\n",
        "\t\t\t\t\tclass_mode= 'binary')\n",
        "\n",
        "test_loss_original, test_acc_original = model.evaluate(test_generator, steps = 25)\n",
        "print('\\ntest acc :\\n', test_acc_original)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_imgs = test_generator[0][0]\n",
        "#test_labels = test_generator[0][1]\n",
        "\n",
        "\n",
        "#predictions = model.predict(test_imgs)\n",
        "#classes_x = np.argmax(predictions,axis=1)\n",
        "#classes_x"
      ],
      "metadata": {
        "id": "geC1ZUjTgWXH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Model         ', 'test loss            ', ' test accuracy ')\n",
        "#print('Original      ', test_loss_original, '   ', test_acc_original)\n",
        "#print('More Layers   ', test_loss_cnn, '   ', test_acc_cnn)\n",
        "#print('Transfer VGG  ', test_loss_vgg, '  ', test_acc_vgg)\n",
        "\n",
        "\n",
        "from tensorflow.math import confusion_matrix\n",
        "\n",
        "#mat = confusion_matrix(classes_x, test_labels)\n",
        "#print('         ', 'label neg ', ' label pos')\n",
        "#print('pred neg    ', np.array(mat[0][0]), \"        \", np.array(mat[0][1]))\n",
        "#print('pred pos    ', np.array(mat[1][0]), \"         \", np.array(mat[1][1]))"
      ],
      "metadata": {
        "id": "FV_Q7LyfW1ka"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
