# -*- coding: utf-8 -*-
"""MvsW2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13Qk6IHWUndxFw6N3RgSPdlEJcBvvpILq
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/"
!ls

"""# Data Augmentation

usamos ImageDataGenerator para generar imagenes nuevas en el ram mientras entrenamos para no desperdiciar espacio.
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator


base_dir = 'Fotos'
train_dir = os.path.join(base_dir,'train')
test_dir = os.path.join(base_dir, 'test')

train_datagen = ImageDataGenerator(
							rescale = 1./255, #obligatorio
							rotation_range = 40,
							#width_shift_range = 0.2,
							#height_shift_range = 0.2,
							#shear_range = 0.3,
							zoom_range = 0.3,
							horizontal_flip = True)

train_generator = train_datagen.flow_from_directory(
							train_dir,
							target_size = (150, 150),
							batch_size = 128,
							class_mode ='binary'
							)

from tensorflow.keras import optimizers
from tensorflow.keras import models
from tensorflow.keras import layers

model = models.Sequential()
model.add(layers.Conv2D(16, (3, 3), activation="relu", input_shape = (150,150,3)))
model.add(layers.MaxPooling2D())
model.add(layers.Conv2D(32, (3, 3), activation="relu", input_shape = (150,150,3)))
model.add(layers.MaxPooling2D())
model.add(layers.Conv2D(64, (3, 3), activation="relu", input_shape = (150,150,3)))
model.add(layers.MaxPooling2D())
model.add(layers.Flatten())
model.add(layers.Dense(128,activation='relu'))
model.add(layers.Dense(1,activation='sigmoid'))

model.summary()

model.compile(loss='binary_crossentropy',
						optimizer=optimizers.RMSprop(learning_rate=2e-5),
						metrics=['acc'])

history = model.fit(
						train_generator,
						epochs = 10)


acc = history.history['acc']
loss = history.history['loss']

epochs = range(1, len(acc)+1)

plt.plot(epochs,acc,'bo',label='train accuracy')
plt.title('train acc')
plt.legend()

plt.figure()

plt.plot(epochs,loss, 'bo', label ='training loss')
plt.title('train loss')
plt.legend()

plt.show()

test_datagen = ImageDataGenerator(1./255)
test_generator = test_datagen.flow_from_directory(
					test_dir,
					target_size = (150, 150),
					batch_size = 64,
					class_mode= 'binary')

test_loss_original, test_acc_original = model.evaluate(test_generator, steps = 25)
print('\ntest acc :\n', test_acc_original)

#test_imgs = test_generator[0][0]
#test_labels = test_generator[0][1]


#predictions = model.predict(test_imgs)
#classes_x = np.argmax(predictions,axis=1)
#classes_x

#print('Model         ', 'test loss            ', ' test accuracy ')
#print('Original      ', test_loss_original, '   ', test_acc_original)
#print('More Layers   ', test_loss_cnn, '   ', test_acc_cnn)
#print('Transfer VGG  ', test_loss_vgg, '  ', test_acc_vgg)


from tensorflow.math import confusion_matrix

#mat = confusion_matrix(classes_x, test_labels)
#print('         ', 'label neg ', ' label pos')
#print('pred neg    ', np.array(mat[0][0]), "        ", np.array(mat[0][1]))
#print('pred pos    ', np.array(mat[1][0]), "         ", np.array(mat[1][1]))
